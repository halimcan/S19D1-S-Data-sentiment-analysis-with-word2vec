{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec ile duygu analizi\n",
    "\n",
    "### AlÄ±ÅŸtÄ±rma hedefleri:\n",
    "- Word2Vec ile kelimeleri vektÃ¶rlere dÃ¶nÃ¼ÅŸtÃ¼rmek\n",
    "- Word2vec tarafÄ±ndan verilen kelime temsilini RNN'ye beslemek iÃ§in kullanmak\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â–¶ï¸ Bu hÃ¼creyi Ã§alÄ±ÅŸtÄ±rÄ±n ve kullandÄ±ÄŸÄ±nÄ±z ğŸ“š [Gensim - Word2Vec](https://radimrehurek.com/gensim/auto_examples/index.html) sÃ¼rÃ¼mÃ¼nÃ¼n â‰¥ 4.0 olduÄŸundan emin olun!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze | grep gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Veri\n",
    "\n",
    "\n",
    "â“ **Soru** â“ Ã–ncelikle verileri yÃ¼kleyelim. Fonksiyonda neler olduÄŸunu anlamanÄ±za gerek yok, burada Ã¶nemi yok.\n",
    "\n",
    "âš ï¸ **UyarÄ±** âš ï¸ `load_data` fonksiyonunda `percentage_of_sentences` argÃ¼manÄ± vardÄ±r. BilgisayarÄ±nÄ±za baÄŸlÄ± olarak, Ã§ok fazla cÃ¼mle bilgisayarÄ±nÄ±zÄ± yavaÅŸlatabilir veya hatta dondurabilir - RAM'iniz taÅŸabilir. Bu nedenle, **cÃ¼mlelerin %10'uyla baÅŸlamalÄ±** ve bilgisayarÄ±nÄ±zÄ±n bunu kaldÄ±rabildiÄŸini kontrol etmelisiniz. Aksi takdirde, daha dÃ¼ÅŸÃ¼k bir sayÄ± ile yeniden Ã§alÄ±ÅŸtÄ±rÄ±n. \n",
    "\n",
    "âš ï¸ **DISCLAIMER** âš ï¸ **_En bÃ¼yÃ¼ÄŸÃ¼ kimde_ (_who has the biggest_)(RAM) oyununu oynamaya gerek yok!** Buradaki amaÃ§, modellerinizi hÄ±zlÄ± bir ÅŸekilde Ã§alÄ±ÅŸtÄ±rarak prototip oluÅŸturmaktÄ±r. GerÃ§ek hayatta bile, hÄ±zlÄ± bir ÅŸekilde dÃ¶ngÃ¼ ve hata ayÄ±klama yapmak iÃ§in verilerinizin bir alt kÃ¼mesiyle baÅŸlamanÄ±z Ã¶nerilir. Bu nedenle, yalnÄ±zca en iyi doÄŸruluÄŸu elde etmek istiyorsanÄ±z sayÄ±yÄ± artÄ±rÄ±n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "### Verileri yÃ¼klemek iÃ§in bu hÃ¼creyi Ã§alÄ±ÅŸtÄ±rÄ±n ###\n",
    "####################################################\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "def load_data(percentage_of_sentences=None):\n",
    "    train_data, test_data = tfds.load(name=\"imdb_reviews\", split=[\"train\", \"test\"], batch_size=-1, as_supervised=True)\n",
    "\n",
    "    train_sentences, y_train = tfds.as_numpy(train_data)\n",
    "    test_sentences, y_test = tfds.as_numpy(test_data)\n",
    "\n",
    "    # TÃ¼m verilerin yalnÄ±zca belirli bir yÃ¼zdesini alÄ±n\n",
    "    if percentage_of_sentences is not None:\n",
    "        assert(percentage_of_sentences> 0 and percentage_of_sentences<=100)\n",
    "\n",
    "        len_train = int(percentage_of_sentences/100*len(train_sentences))\n",
    "        train_sentences, y_train = train_sentences[:len_train], y_train[:len_train]\n",
    "\n",
    "        len_test = int(percentage_of_sentences/100*len(test_sentences))\n",
    "        test_sentences, y_test = test_sentences[:len_test], y_test[:len_test]\n",
    "\n",
    "    X_train = [text_to_word_sequence(_.decode(\"utf-8\")) for _ in train_sentences]\n",
    "    X_test = [text_to_word_sequence(_.decode(\"utf-8\")) for _ in test_sentences]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "X_train, y_train, X_test, y_test = load_data(percentage_of_sentences=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ã–nceki alÄ±ÅŸtÄ±rmada, Word2vec temsilini eÄŸittiniz ve bu Åekil'in ilk adÄ±mÄ±nda gÃ¶sterildiÄŸi gibi, tÃ¼m eÄŸitim cÃ¼mlelerinizi bir RNN'ye beslemek iÃ§in dÃ¶nÃ¼ÅŸtÃ¼rdÃ¼nÃ¼z: \n",
    "\n",
    "<img src=\"https://wagon-public-datasets.s3.amazonaws.com/data-science-images/06-DL/NLP/word2vec_representation.png\" alt=\"Word2Vec with RNN\" width=\"400px\" />\n",
    "\n",
    "\n",
    "\n",
    "â“ **Soru** â“ Burada, Ã¶nceki alÄ±ÅŸtÄ±rmada yaptÄ±ÄŸÄ±nÄ±zÄ±n aynÄ±sÄ±nÄ± tekrar yapalÄ±m. Ä°lk olarak, eÄŸitim cÃ¼mleniz Ã¼zerinde bir word2vec modeli (istediÄŸiniz argÃ¼manlarla) eÄŸitin. Bunu `word2vec` deÄŸiÅŸkenine kaydedin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# SENÄ°N KODUN BURAYA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ã–nceki alÄ±ÅŸtÄ±rmadaki iÅŸlevleri yeniden kullanarak, eÄŸitim ve test verilerinizi RNN'ye girebileceÄŸiniz bir biÃ§ime dÃ¶nÃ¼ÅŸtÃ¼relim.\n",
    "\n",
    "â“ **Soru** â“ Neler olduÄŸunu anladÄ±ÄŸÄ±nÄ±zdan emin olmak iÃ§in aÅŸaÄŸÄ±daki iÅŸlevi okuyun ve Ã§alÄ±ÅŸtÄ±rÄ±n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "# Bir cÃ¼mleyi (kelime listesi) gÃ¶mme uzayÄ±ndaki kelimeleri temsil eden bir matrise dÃ¶nÃ¼ÅŸtÃ¼rme iÅŸlevi\n",
    "def embed_sentence(word2vec, sentence):\n",
    "    embedded_sentence = []\n",
    "    for word in sentence:\n",
    "        if word in word2vec.wv:\n",
    "            embedded_sentence.append(word2vec.wv[word])\n",
    "\n",
    "    return np.array(embedded_sentence)\n",
    "\n",
    "# Bir cÃ¼mle listesini matris listesine dÃ¶nÃ¼ÅŸtÃ¼ren iÅŸlev\n",
    "def embedding(word2vec, sentences):\n",
    "    embed = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        embedded_sentence = embed_sentence(word2vec, sentence)\n",
    "        embed.append(embedded_sentence)\n",
    "\n",
    "    return embed\n",
    "\n",
    "# EÄŸitim ve test cÃ¼mlelerini gÃ¶mÃ¼n(embed edin)\n",
    "X_train_embed = embedding(word2vec, X_train)\n",
    "X_test_embed = embedding(word2vec, X_test)\n",
    "\n",
    "\n",
    "# EÄŸitim ve test gÃ¶mÃ¼lÃ¼ cÃ¼mleleri doldurun\n",
    "X_train_pad = pad_sequences(X_train_embed, dtype='float32', padding='post', maxlen=200)\n",
    "X_test_pad = pad_sequences(X_test_embed, dtype='float32', padding='post', maxlen=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â˜ï¸ Ã‡alÄ±ÅŸtÄ±ÄŸÄ±ndan emin olmak iÃ§in, `X_train_pad` ve `X_test_pad` iÃ§in aÅŸaÄŸÄ±dakileri kontrol edelim:\n",
    "\n",
    "- bunlar numpy dizileridir\n",
    "- bunlar 3 boyutludur\n",
    "- son boyut, word2vec gÃ¶mme alanÄ±nÄ±zÄ±n boyutundadÄ±r (bunu `word2vec.wv.vector_size` ile elde edebilirsiniz\n",
    "- ilk boyut, `X_train` ve `X_test` boyutundadÄ±r\n",
    "\n",
    "âœ… **Ä°yi Uygulama** âœ… Bu tÃ¼r testler oldukÃ§a Ã¶nemlidir! Sadece bu alÄ±ÅŸtÄ±rmada deÄŸil, gerÃ§ek hayattaki uygulamalarda da. HatalarÄ± Ã§ok geÃ§ fark etmeyi ve bunlarÄ±n tÃ¼m not defterine yayÄ±lmasÄ±nÄ± Ã¶nler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BENÄ° TEST ET\n",
    "for X in [X_train_pad, X_test_pad]:\n",
    "    assert type(X) == np.ndarray\n",
    "    assert X.shape[-1] == word2vec.wv.vector_size\n",
    "\n",
    "\n",
    "assert X_train_pad.shape[0] == len(X_train)\n",
    "assert X_test_pad.shape[0] == len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temel model\n",
    "\n",
    "Kendi modelinizi test etmek iÃ§in Ã§ok basit bir modele sahip olmak her zaman iyidir - Ã§ok basit bir algoritmadan daha iyi bir ÅŸey yaptÄ±ÄŸÄ±nÄ±zdan emin olmak iÃ§in.\n",
    "\n",
    "â“ **Soru** â“ Temel doÄŸruluk oranÄ±nÄ±z nedir? Bu durumda, temeliniz `y_train` iÃ§inde en Ã§ok bulunan etiketi tahmin etmek olabilir (tabii ki, veri kÃ¼mesi dengeli ise, temel doÄŸruluk oranÄ± 1/n'dir; burada n, sÄ±nÄ±flarÄ±n sayÄ±sÄ±dÄ±r - burada 2'dir)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# SENÄ°N KODUN BURAYA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "â“ **Soru** â“ AÅŸaÄŸÄ±daki katmanlara sahip bir RNN yazÄ±n:\n",
    "- bir `Masking` katmanÄ±\n",
    "- 20 birim ve `tanh` aktivasyon fonksiyonuna sahip bir `LSTM`\n",
    "- 10 birimlik bir `Dense`\n",
    "- gÃ¶revinize baÄŸlÄ± bir Ã§Ä±ktÄ± katmanÄ±\n",
    "\n",
    "ArdÄ±ndan, modelinizi derleyin (en azÄ±ndan baÅŸlangÄ±Ã§ta optimizer olarak `rmsprop` kullanmanÄ±zÄ± Ã¶neririz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# SENÄ°N KODUN BURAYA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ **Soru** â“ Modeli gÃ¶mÃ¼lÃ¼ ve doldurulmuÅŸ verilerinize uyarlayÄ±n - erken durdurma kriterini unutmayÄ±n.\n",
    "\n",
    "â— **Not** â— DoÄŸruluÄŸunuz bÃ¼yÃ¼k Ã¶lÃ§Ã¼de eÄŸitim kÃ¼menize baÄŸlÄ± olacaktÄ±r. Burada, performansÄ±nÄ±zÄ±n temel modelin Ã¼zerinde olduÄŸundan emin olun (bu, baÅŸlangÄ±Ã§taki IMDB verilerinin yalnÄ±zca %20'sini yÃ¼klemiÅŸ olsanÄ±z bile geÃ§erli olmalÄ±dÄ±r)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# SENÄ°N KODUN BURAYA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ **Soru** â“ Test setinde modelinizi deÄŸerlendirin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# SENÄ°N KODUN BURAYA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EÄŸitimli Word2Vec - Transfer Ã–ÄŸrenimi\n",
    "\n",
    "DoÄŸruluÄŸunuz, temel modelin Ã¼zerinde olsa da, oldukÃ§a dÃ¼ÅŸÃ¼k olabilir. Veri temizleme ve gÃ¶mme kalitesini iyileÅŸtirme gibi bunu iyileÅŸtirmek iÃ§in birÃ§ok seÃ§enek vardÄ±r.\n",
    "\n",
    "Burada veri temizleme stratejilerine girmeyeceÄŸiz. GÃ¶mme kalitemizi iyileÅŸtirmeye Ã§alÄ±ÅŸalÄ±m. Ancak, daha bÃ¼yÃ¼k bir metin kÃ¼mesini yÃ¼klemek yerine, neden baÅŸkalarÄ±nÄ±n Ã¶ÄŸrendiÄŸi gÃ¶mme modelinden yararlanmayalÄ±m? Ã‡Ã¼nkÃ¼ gÃ¶mme modelinin kalitesi, yani kelimelerin yakÄ±nlÄ±ÄŸÄ±, farklÄ± gÃ¶revlerden elde edilebilir. Transfer Ã¶ÄŸrenme tam olarak budur.\n",
    "\n",
    "â“ **Soru** â“ Bu sayede word2vec'te bulunan tÃ¼m farklÄ± modelleri listeleyin: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "print(list(api.info()['models'].keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â„¹ï¸ Modellerin listesini ve boyutlarÄ±nÄ± [`gensim-data` deposunda](https://github.com/RaRe-Technologies/gensim-data#models) de bulabilirsiniz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ **Soru** â“ Ã–nceden eÄŸitilmiÅŸ word2vec gÃ¶mme alanlarÄ±ndan birini yÃ¼kleyin.\n",
    "\n",
    "Bunu `api.load(seÃ§tiÄŸiniz model)` ile yapabilir ve `word2vec_transfer` iÃ§inde saklayabilirsiniz.\n",
    "\n",
    "<details>\n",
    "    <summary>ğŸ’¡ Ä°pucu</summary>\n",
    "    \n",
    "`glove-wiki-gigaword-50` modeli, daha kÃ¼Ã§Ã¼k olmasÄ± (65 MB) nedeniyle baÅŸlangÄ±Ã§ iÃ§in iyi bir seÃ§enektir.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# SENÄ°N KODUN BURAYA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ **Soru** â“ Kelime daÄŸarcÄ±ÄŸÄ±nÄ±n boyutunu ve aynÄ± zamanda gÃ¶mme alanÄ±nÄ±n boyutunu kontrol edin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# SENÄ°N KODUN BURAYA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ Ä°lk soruda yaptÄ±ÄŸÄ±mÄ±z gibi, `X_train` ve `X_test`'i gÃ¶melim! (`embed_sentence_with_TF` iÅŸlevinde kÃ¼Ã§Ã¼k bir fark var, ancak bu konuya girmeyeceÄŸiz.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bir cÃ¼mleyi (kelime listesi) gÃ¶mme uzayÄ±ndaki kelimeleri temsil eden bir matrise dÃ¶nÃ¼ÅŸtÃ¼rme iÅŸlevi\n",
    "def embed_sentence_with_TF(word2vec, sentence):\n",
    "    embedded_sentence = []\n",
    "    for word in sentence:\n",
    "        if word in word2vec:\n",
    "            embedded_sentence.append(word2vec[word])\n",
    "\n",
    "    return np.array(embedded_sentence)\n",
    "\n",
    "# Bir cÃ¼mle listesini matris listesine dÃ¶nÃ¼ÅŸtÃ¼ren iÅŸlev\n",
    "def embedding(word2vec, sentences):\n",
    "    embed = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        embedded_sentence = embed_sentence_with_TF(word2vec, sentence)\n",
    "        embed.append(embedded_sentence)\n",
    "\n",
    "    return embed\n",
    "\n",
    "# EÄŸitim ve test cÃ¼mlelerini gÃ¶mÃ¼n (embed edin)\n",
    "X_train_embed_2 = embedding(word2vec_transfer, X_train)\n",
    "X_test_embed_2 = embedding(word2vec_transfer, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ **Soru** â“  SonuÃ§larÄ±nÄ±zÄ± doldurmayÄ± ve bunlarÄ± `X_train_pad_2` ve `X_test_pad_2` iÃ§inde saklamayÄ± unutmayÄ±n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# SENÄ°N KODUN BURAYA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ **Soru** â“ Modeli yeniden baÅŸlatÄ±n ve yeni gÃ¶mÃ¼lÃ¼ (ve doldurulmuÅŸ(padded)) verilerinize uyarlayÄ±n!  Test setinizde deÄŸerlendirin ve Ã¶nceki doÄŸruluÄŸunuzla karÅŸÄ±laÅŸtÄ±rÄ±n.\n",
    "\n",
    "â— **Not** â— Buradaki eÄŸitim biraz zaman alabilir. Sadece 10 dÃ¶nem hesaplayabilir (bu **iyi** bir uygulama deÄŸildir, sadece Ã§ok uzun sÃ¼re beklememek iÃ§indir) ve eÄŸitim sÃ¼rerken bir sonraki alÄ±ÅŸtÄ±rmaya geÃ§ebilir veya bir mola verebilirsiniz, muhtemelen bunu hak ettiniz ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# SENÄ°N KODUN BURAYA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.evaluate(X_test_pad_2, y_test, verbose=0)\n",
    "\n",
    "print(f'The accuracy evaluated on the test set is of {res[1]*100:.3f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yeni word2vec'iniz bÃ¼yÃ¼k bir metin kÃ¼mesinde eÄŸitildiÄŸinden, Ã§ok sayÄ±da kelimeyi temsil eder! KÃ¼Ã§Ã¼k veri kÃ¼menize kÄ±yasla Ã§ok daha fazladÄ±r, Ã¶zellikle de eÄŸitim kÃ¼mesinde belirli bir sayÄ±dan fazla bulunmayan kelimeleri elediÄŸiniz iÃ§in. Bu nedenle, eÄŸitim ve test kÃ¼menizde Ã§ok daha fazla gÃ¶mÃ¼lÃ¼ kelime vardÄ±r, bu da her yinelemeyi Ã¶ncekinden daha uzun hale getirir."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
